<!doctype html>
<head>
<meta charset="utf-8">
<link rel="stylesheet" id="typeplate-css" href="../css/typeplate.css">
<link rel="stylesheet" href="../css/demo.css">
<link rel="stylesheet" href="../css/local.css">
<link rel="stylesheet" href="../highlightjs/styles/tomorrow.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css">

<script src="../highlightjs/highlight.pack.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<meta name="author" content="Ahmed Fasih">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
<title>Aldebrn Maps: texture-shaded terrain visualization</title>
<style>
code, .code {
  color: #f99157;
}
</style>

</head>

<body>
<article role="article">

<p><a href="../index.html">(back to main)</a></p>

<header>
	<h1 class="typl8-beta">Matlab: replicate columns of a matrix an arbitrary number of times</h1>
  <h2><small>A code story by <cite>Ahmed Fasih</cite> <small>2016/5/30</small></small></h2>
</header>

<p class="typl8-delta lede">
We needed to replicate each column of an array a potentially different number of times in Matlab. This is how we did it. But this is also a little about the process we went through to get to where we finally got. Writing is a nonlinear activity. Writing code is no exception.
</p>

<p class="typl8-drop-cap">
We‚Äôve got a matrix <code>P</code>. In Matlab, this means a 2D array of numbers. It has  <code>widthP</code> columns and the number of rows doesn‚Äôt matter. We need a second matrix <code>M</code> that contains each column of the first matrix, <code>P</code>, repeated an arbitrary number of times. A vector <code>reps</code>, containing <code>widthP</code> entries, tells you how many times any given column of <code>P</code> is replicated.</p>

<p>E.g. If <code>P = [42 -1 101]</code> and <code>reps = [4 2 3]</code>, we want <code>M = [42 42 42 42 -1 -1 101 101 101]</code>, assuming I typed that correctly.</p>

<p>We had a working implementation that profiling revealed to be a bottleneck. Here‚Äôs how we went about optimizing this.</p>

<h2 id="s1" class="typl8-gamma">First attempt</h2>
<p>Create a standalone script which sets up some random data, and a correct implementation. (The one here is actually <em>simpler</em> than the technique we started out with.)</p>

<pre><code class="matlab">P = [42 -1 101];
reps = [2 1 5];

widthP = length(reps);
M = [];
for colIdx = 1 : length(reps)
  M = [M repmat(P(:, colIdx), 1, reps(colIdx))];
end
</code></pre>

<p>(As (unwilling) professional Matlab writers, we wouldn‚Äôt have written this to start out with since, (i) <code>for</code> loops are still best avoided in Matlab (‚ÄúInstead of writing loop-based code, consider using MATLAB matrix and vector operations‚Äù <a href="http://www.mathworks.com/help/matlab/matlab_prog/techniques-for-improving-performance.html">(Mathworks)</a>), and (ii) re-allocating storage every iteration will be slow in any system.</p>

<h2 id="s2" class="typl8-gamma">Some more fancy</h2>

<p>Find ways to do the same thing faster. Here‚Äôs the approach we actually started out with:</p>
<pre><code class="matlab">c = arrayfun(@(n, i) i*ones(n,1), reps, 1:widthP, 'un', 0);
i = cell2mat(c(:));
M2 = P(:, i);
assert(all(M2(:) == M(:)))
</code></pre>
<p><code>arrayfun</code> <a href="http://www.mathworks.com/help/matlab/ref/arrayfun.html">(docs)</a> is a lame <code>map</code>: taking a function handle (viz., <code>@(n, i) i*ones(n,1)</code>) and any number of arrays, and returning a cell array‚Äîwhich are Matlab‚Äôs arbitrary-type arrays.</p>

<p>What we‚Äôre doing here is building a vector <code>i</code>, with repeated values, which we‚Äôll use to index into our original array <code>P</code>. This does what we need because in Matlab, indexing an array with a vector containing repeats produces a result array containing repeats. Same story in Python/Numpy (0-indexed!):
<pre><code class="python">import numpy as np
np.array([10, 20, 30])[[0,1,2,1,0,1,2]]
#=> array([10, 20, 30, 20, 10, 20, 30])</code></pre>

and Julia (1-indexed):

<pre><code class="julia">[10 20 30][[1 2 3 2 1 2 3]]
#=> 1x7 Array{Int64,2}:
#=>  10  20  30  20  10  20  30
</code></pre>
</p>

<p>We make sure all this fancy indexing works, in our Matlab code snippet, by comparing <code>M2</code> to the <code>M</code> generated by the first implementation: <code>assert(all(M2(:) == M(:)))</code>. </p>

<p>
(<code>assert</code> is a common function across programming languages that unceremoniously throws an error and halts program execution if its argument is false.)
</p>

<p>This way of building a big matrix out of a smaller matrix‚Äîusing an index vector‚Äîis a really fast way to build that big matrix. We knew that because profiling showed the bottleneck to be before indexing into <code>P</code>. So we just need to find a way to efficiently build this index vector <code>i</code>.</p>

<p>As mentioned above, this was actually the code we started out with. Why think we could do better than this? From the days of Tom Minka‚Äôs Lightspeed package <a href="http://research.microsoft.com/en-us/um/people/minka/software/lightspeed/">[Microsoft Research]</a>, we‚Äôve known that the built-in <code>repmat</code> and even <code>ones</code> can be inefficient (<code>bsxfun</code> FTW!). Also, empirical experience over the years tells me that <code>cell2mat</code> makes things unfast.</p>

<h2 id="s3" class="typl8-gamma">Inspiration for speed</h2>

<p>I started sketching‚Äîyou know, pen and paper. A few minutes later, I had something fast but unreadable. I‚Äôll show it in a second, but here‚Äôs the central idea. Remember the example we started out with, <code>reps = [4 2 3]</code>. The index vector we want to make is:
  <figure>
    <span id="k1"></span><script>
    katex.render(`
i = \\begin{bmatrix}
1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\
2 \\\\ 2 \\\\
3 \\\\ 3 \\\\ 3
\\end{bmatrix}
= cumsum\\left(
\\begin{bmatrix}
1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\
1 \\\\ 0 \\\\
1 \\\\ 0 \\\\ 0
\\end{bmatrix}
\\right)
,`, document.getElementById('k1'));</script>
  </figure>
where <code>cumsum</code> is the cumulative sum (a.k.a. prefix sum, scan, ‚Ä¶). Staring at the vector being cumulatively summed (the second vector to the right), it dawned on me that it was non-zero only where a new group of indexes begins, i.e., at the boundary between 1 and 2, and between 2 and 3. If I could generate this boolean vector of zeros-and-ones efficiently‚Äîand betting that <code>cumsum</code> is fast‚ÄîI could have an efficient way to generate the index vector <code>i</code>. I called the boolean vector <code>z</code> (‚Äúzeros, mostly‚Äù as the mnemonic).
</p>

<p>This next part is a little ugly. I could have logically and formally reasoned out how to calculate which indexes of a vector-of-zeros to flip on to obtain <code>z</code>. I couldn‚Äôt be bothered with all that, so I did something I often do‚Äîjust came up with code that worked for this exact numerical example: ‚Äúthe rule must involve <code>reps</code>, another <code>cumsum</code>, hrm the dimensions won‚Äôt line up, just ignore the last element‚Ä¶‚Äù It turned out that the rule discovered in this way does work for the general case.

<pre><code class="matlab">widthM = sum(reps);
% vector to be cumsummed
z = zeros(widthM, 1);
% indexes of z to be 1 (otherwise z is 0)
j = [1 1 + cumsum(reps(1 : end - 1))]; % üå∂ pixie dust, not much
z(j) = 1;
% as promised, cumsum z to get i:
i = cumsum(z);
% use i to index into P:
M3 = P(:, i);
% Works right?
assert(all(M3(:) == M(:)))
</code></pre>
</p>

<p>The code (minus the comments) follows the stream-of-consciousness narrative above because it was written during it. The pixie dust in finding the indexes of non-zero <code>z</code> (<code>j</code> above, because it‚Äôs an index like <code>i</code>)‚Äîit works, but it‚Äôs not easy to see or to explain. This isn‚Äôt academia so I can tell you‚ÄîI got lucky. In this case, the stupid shot in the dark worked. Furthermore, I don‚Äôt have to impress you with a mountain of mathematical exposition ‚Äúshowing‚Äù you how or why this works‚Äîtruth is, I don‚Äôt know (I mean, I can squint at it and see that it works, but that‚Äôs not ‚Äúknowing‚Äù). Had this code <em>not</em> worked, I‚Äôd have looked at how it fails, and patched up the implementation to avoid that failure mode, and try again. I think this is how I usually code when someone hasn‚Äôt given me a formal algorithm to implement.</p>

<p>Actually, this code doesn‚Äôt work in the absolutely general case, when <code>reps</code> contains 0 (meaning, some columns of input <code>P</code> aren‚Äôt in output <code>M</code>). The code fails in an interesting way, but the fix isn‚Äôt that interesting: filter <code>reps</code> to be non-zero, run the above algorithm to generate <code>i</code> and shift it around to account for those 0-repeated indexes to get a corrected index vector <code>i2</code>. Here‚Äôs that full code:

<pre><code class="matlab">nzidx = reps~=0;
nzreps = reps(nzidx);

% reps != 0 algorithm as above, except using nzreps instead of reps
widthM = sum(reps);
z = zeros(widthM, 1);
j = [1 1 + cumsum(nzreps(1 : end - 1))]; % üå∂ pixie dust, not much
z(j) = 1;
i = cumsum(z);

% adjust i
n = 1:numel(reps);
f = n(nzidx);
i2 = f(i);

M3 = P(:, i2);
assert(all(M3(:) == M(:)))
</code></pre>
</p>

<h2 id="step3" class="typl8-gamma">Timings, or, Real Engineering</h2>
<p>Now that we had a couple of alternative implementations that we hope are fast, it‚Äôs time to benchmark speed and test generality.</p>

<p>Matlab is an exceedingly clumsy language:
  <ol>
    <li>
      anonymous functions are single expressions, and so cannot contain <code>if</code>, <code>for</code>, multiple statements of any kind (same story in Python, but that has other features that lessen the pain, without eliminating it).
    </li>
    <li>
       Second, Matlab assignment and indexing have to be statements, so they cannot be inside anonymous functions.
    </li>
    <li>
      Finally, Matlab requires (sub)functions to be defined in a function file, not a script file. (JavaScript and Clojure are <em>far</em> less brutalist. Less brutal too.)
    </li>
  </ol>
As a result of this constellation of inadequacies (to which we‚Äôve long resigned ourselves), we had to convert our simple easy-to-understand script file to a more opaque and less flexible function file. You can read it in full at its <a href="https://gist.github.com/fasiha/b5e8b1d61886cbe2583febde6a3fb42f">[Gist]</a>. The software carpentry aspect I want to point out is timing in Matlab: after checking that all three methods yield the correct answer for large, randomly generated inputs, we used <code>timeit</code> to run each implementation many times, and normalize the runtimes by the first implementation.</p>

<pre><code class="matlab">t1 = timeit(@() method1(reps, P));
t2 = timeit(@() method2(reps, P));
t3 = timeit(@() method3(reps, P));
relativeTimes = [t1 t2 t3] / t1</code></pre>

<p>We found that, for <code>P</code> 10√ó1000, and each of the thousand columns repeated between 0 and 39 times,
<ul>
 <li>method 2 (<code>arrayfun</code>, <code>cell2mat</code>) runtime is 1.4√ó (slower!) than method 1, and</li>
 <li>method 3 (pixie dust, <code>cumsum</code>) runtime is 0.08√ó (much faster!) than method 1.</li>
</ul>
<p>Compared to the code we originally started out with (method 2 here), the final code runs 14√ó faster. Now, many other parts of the application dominate runtime, but not this part.
</p>

<p>In summary, the three steps we followed, and that I‚Äôve done countless times, are
  <ol>
    <li>profile to see what‚Äôs slow, then</li>
    <li>
      carve out that piece into its own file, with some test data and a reference implementation.
    </li>
    <li>
      Then, in parallel:
      <ol>
        <li>
           think very hard and find ways to make it go faster while remaining correct, and
        </li>
        <li>
          time the code.
        </li>
      </ol>
    </li>
  </ol>
  Think-and-profile may need to be run for several iterations.
</p>

<h2 id="postscript" class="typl8-gamma">Postscripts</h2>

<p>The above discussion presumes that you are lucky enough to identify a juicy candidate for optimization. In Matlab, with mostly-math code, this is often the case in my experience. In larger applications that do many things besides number-crunching, the inefficiencies may be spread throughout the codebase. A reasonable statement of the two schools of thought is via one of Karsten Schmidt‚Äôs workshop report <a href="https://medium.com/@thi.ng/workshop-report-hi-perf-clojurescript-with-webgl-asm-js-and-emscripten-a545cca083bc#.7tp0znhyn">[Medium]</a>.</p>

<p>
That said, perhaps the best restatement of what we found is this:
  <aside class="typl8-pull-quote">
    <blockquote>
      <p> You must measure everything. We all have intuition. And the intuition of programmers is ‚Ä¶ always wrong. Outdated. Intuition ignores a lot of aspects of a complex reality. Today‚Äôs machine architectures are so complicated, there‚Äôre so many variables in flight at any point in time that it‚Äôs essentially impossible to consider them deterministic machines any more. They are not deterministic any more. <strong>So we make very often big mistakes when assuming things about what‚Äôs going to make fast code.</strong> [E.g.,] fewer instructions ‚â† faster code. Data [access] is not always faster than computation. The only good intuition is ‚ÄúI should measure this stuff and see what happens.‚Äù</p>
      <p>
      To quote a classic, who is still alive: Walter Bight: ‚ÄúMeasuring gives you a leg up on experts who are so good they don‚Äôt need to measure.‚Äù Walter and I have been working on optimizing bits and pieces of a project we work on [the D programming language] and ‚Ä¶ <strong><em>whenever we think we know what we‚Äôre doing, we measure, and it‚Äôs just the other way around.</em></strong></p>
    </blockquote>
    <figcaption><small>
      Andrei Alexandrescu, <cite>Writing Quick Code in C++, Quickly</cite>, GoingNative 2013 <a href="https://youtu.be/ea5DiCg8HOY?t=5m32s">[YouTube]</a>
    </small></figcaption>
  </aside>

 We experienced Dr Alexandrescu‚Äôs comments about measurements disconfirming intuition first-hand above, when method 2 (<code>arrayfun</code>, <code>cell2mat</code>), which we started out with, was <em>slower</em> than method 1 (<code>for</code> loop, with array reallocation every loop)!</p>

<p><strong>Post-postscript.</strong> <code>timeit</code> was submitted to <a href="http://www.mathworks.com/matlabcentral/fileexchange/18798">[Mathworks File Exchange]</a> in 2008 and made it into Matlab proper in 2013. Python 2.3, from 2003, had this built-in.</p>


</article>
</body>
